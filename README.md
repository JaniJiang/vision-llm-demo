# vision-llm-demo

A demonstration of an end-to-end **multimodal AI pipeline**.  
This project integrates **image + text inputs** with a large language model (LLM) to perform vision-language reasoning.  

---

## ðŸš€ Features
- Convert images to **Base64** for model compatibility
- Combine **image + natural language queries** into a single prompt
- Call an **OpenAI-compatible multimodal API** for inference
- Output **structured model responses**
- Includes workflow diagram for clarity

---
## ðŸ–¼ Workflow
<img width="511" height="541" alt="Screenshot 2025-09-26 at 6 52 07â€¯PM" src="https://github.com/user-attachments/assets/2fbe25bd-a633-456a-9985-7a52e6d7ddc1" />


## ðŸ“‚ Project Structure

